# nginx.conf for load balancing multiple API instances

events {
    worker_connections 1024;
}

http {
    # Load balancing configuration
    upstream api_backend {
        least_conn;  # Use least connections algorithm
        server api1:8080 max_fails=3 fail_timeout=30s;
        server api2:8080 max_fails=3 fail_timeout=30s;
        server api3:8080 max_fails=3 fail_timeout=30s;
        
        # Health check
        keepalive 32;
    }

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/s;
    limit_req_zone $binary_remote_addr zone=burst_limit:10m rate=1000r/s;

    # Logging
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';

    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log warn;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml
        text/plain
        text/css
        text/js
        text/xml
        text/javascript;

    # Security headers
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Referrer-Policy strict-origin-when-cross-origin;

    server {
        listen 80;
        listen [::]:80;
        server_name _;

        # Health check endpoint
        location /nginx-health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }

        # API endpoints
        location /api/ {
            # Rate limiting
            limit_req zone=api_limit burst=50 nodelay;
            limit_req zone=burst_limit burst=200 nodelay;

            # Proxy settings
            proxy_pass http://api_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Timeouts
            proxy_connect_timeout 5s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;

            # Buffer settings
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
            proxy_busy_buffers_size 8k;

            # Keep alive
            proxy_http_version 1.1;
            proxy_set_header Connection "";

            # Caching for GET requests
            location ~* ^/api/books/[0-9a-f-]+$ {
                proxy_pass http://api_backend;
                proxy_cache_valid 200 5m;
                proxy_cache_key "$scheme$request_method$host$request_uri";
                add_header X-Cache-Status $upstream_cache_status;
            }
        }

        # Static files (if any)
        location / {
            return 404;
        }
    }

    # SSL/HTTPS configuration (uncomment for production)
    # server {
    #     listen 443 ssl http2;
    #     listen [::]:443 ssl http2;
    #     server_name your-domain.com;
    #
    #     ssl_certificate /etc/nginx/ssl/cert.pem;
    #     ssl_certificate_key /etc/nginx/ssl/key.pem;
    #     ssl_protocols TLSv1.2 TLSv1.3;
    #     ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
    #     ssl_prefer_server_ciphers off;
    #
    #     location /api/ {
    #         limit_req zone=api_limit burst=50 nodelay;
    #         proxy_pass http://api_backend;
    #         # ... same proxy settings as above
    #     }
    # }
}

# Performance tuning for high traffic:
#
# 1. Increase worker_connections based on traffic
# 2. Tune proxy buffer sizes for your response sizes  
# 3. Adjust rate limiting based on expected load
# 4. Enable SSL session caching for HTTPS
# 5. Consider using proxy_cache for frequently accessed data
#
# Expected performance:
# - Can handle 10,000+ concurrent connections
# - Load balances across 3 API instances
# - Built-in rate limiting prevents abuse
# - Gzip compression reduces bandwidth by ~60%
